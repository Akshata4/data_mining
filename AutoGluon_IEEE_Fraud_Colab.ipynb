{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 AutoGluon + Kaggle: IEEE-CIS Fraud Detection (End-to-End)\n",
    "\n",
    "This Colab walks you through a **no-fuss** pipeline to compete seriously on Kaggle's [IEEE-CIS Fraud Detection](https://www.kaggle.com/c/ieee-fraud-detection/) with **AutoGluon**.\n",
    "\n",
    "**What you'll do**\n",
    "1. Install dependencies (`kaggle`, `autogluon`)\n",
    "2. Configure the Kaggle API (upload `kaggle.json`)\n",
    "3. Download the competition data\n",
    "4. Merge CSVs into clean train/test tables\n",
    "5. Train AutoGluon with a strong baseline\n",
    "6. Generate predictions & build `submission.csv`\n",
    "7. Submit to Kaggle from Colab & check leaderboard\n",
    "\n",
    "> **Note**: This competition is large. If you hit RAM limits, toggle the sampling cell to train on a subset for a quick baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ⏬ Step 1: Install dependencies (AutoGluon + Kaggle)\n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install kaggle autogluon.tabular pandas numpy scikit-learn\n",
    "import sys, os, pandas as pd, numpy as np\n",
    "print('Python:', sys.version)\n",
    "import autogluon; print('AutoGluon:', autogluon.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔐 Step 2: Set up your Kaggle API key\n",
    "1. Visit https://www.kaggle.com/account\n",
    "2. Click **Create New API Token** → this downloads `kaggle.json`\n",
    "3. Upload it in the next cell when prompted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title 🔑 Upload kaggle.json and configure permissions\n",
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "\n",
    "uploaded = files.upload()  # select kaggle.json\n",
    "if 'kaggle.json' not in uploaded:\n",
    "    raise SystemExit('Please upload kaggle.json to continue.')\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "print('✅ Kaggle API is set up.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title 📦 Step 3: Download the IEEE-CIS Fraud Detection data via Kaggle API\n",
    "competition = 'ieee-fraud-detection'\n",
    "!mkdir -p data\n",
    "!kaggle competitions download -c {competition} -p data\n",
    "!unzip -oq data/{competition}.zip -d data\n",
    "print('✅ Data downloaded and extracted to ./data')\n",
    "!ls -lh data | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧹 Step 4: Load & merge CSVs into train/test tables\n",
    "\n",
    "- Training = `train_transaction.csv` **left-joined** with `train_identity.csv` on `TransactionID`\n",
    "- Test = `test_transaction.csv` **left-joined** with `test_identity.csv` on `TransactionID`\n",
    "\n",
    "We'll also **downcast** numeric dtypes to reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Load CSVs, merge, and reduce memory usage\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "def reduce_mem_usage(df: pd.DataFrame, verbose=True) -> pd.DataFrame:\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if pd.api.types.is_numeric_dtype(col_type):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if pd.api.types.is_integer_dtype(col_type):\n",
    "                if c_min >= 0:\n",
    "                    if c_max < 255:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif c_max < 65535:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif c_max < 4294967295:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f'Memory: {start_mem:,.2f} MB -> {end_mem:,.2f} MB (↓{start_mem-end_mem:,.2f} MB)')\n",
    "    return df\n",
    "\n",
    "train_tr = pd.read_csv(f\"{DATA_DIR}/train_transaction.csv\", low_memory=False)\n",
    "train_id = pd.read_csv(f\"{DATA_DIR}/train_identity.csv\", low_memory=False)\n",
    "test_tr  = pd.read_csv(f\"{DATA_DIR}/test_transaction.csv\", low_memory=False)\n",
    "test_id  = pd.read_csv(f\"{DATA_DIR}/test_identity.csv\", low_memory=False)\n",
    "\n",
    "print('Merging train...')\n",
    "train = train_tr.merge(train_id, on='TransactionID', how='left')\n",
    "print('Merging test...')\n",
    "test  = test_tr.merge(test_id, on='TransactionID', how='left')\n",
    "\n",
    "del train_tr, train_id, test_tr, test_id\n",
    "print('Reducing memory (train)...')\n",
    "train = reduce_mem_usage(train)\n",
    "print('Reducing memory (test)...')\n",
    "test = reduce_mem_usage(test)\n",
    "\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape :', test.shape)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title (Optional) Use a sample of the data for quicker training\n",
    "USE_SAMPLE = False  #@param {type:\"boolean\"}\n",
    "SAMPLE_FRACTION = 0.25  #@param {type:\"number\"}\n",
    "\n",
    "if USE_SAMPLE:\n",
    "    train = train.sample(frac=SAMPLE_FRACTION, random_state=42)\n",
    "    print('Sampled train shape:', train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 Step 5: Train AutoGluon\n",
    "- Target/label column: **`isFraud`**\n",
    "- We exclude **`TransactionID`** from features\n",
    "- Metric: **ROC AUC** (standard for fraud detection)\n",
    "- Preset: `medium_quality` (good quality vs. training time tradeoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Train AutoGluon TabularPredictor\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "label = 'isFraud'\n",
    "if label not in train.columns:\n",
    "    raise SystemExit(f\"Label column '{label}' not found in training data.\")\n",
    "\n",
    "# Drop ID-like columns that shouldn't be used as signals\n",
    "cols_to_drop = ['TransactionID']\n",
    "train = train.drop(columns=[c for c in cols_to_drop if c in train.columns])\n",
    "test_features = test.drop(columns=[c for c in cols_to_drop if c in test.columns])\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric='roc_auc', problem_type='binary', path='ag_models').fit(\n",
    "    train_data=train,\n",
    "    presets='medium_quality',\n",
    "    time_limit=None  # set to an int (seconds) if you want to cap training time\n",
    ")\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "leaderboard.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Step 6: Predict on test & build `submission.csv`\n",
    "Kaggle expects two columns in `submission.csv`:\n",
    "- `TransactionID`\n",
    "- `isFraud` (probability for class `1`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Generate predictions and create submission file\n",
    "proba = predictor.predict_proba(test_features)\n",
    "\n",
    "import pandas as pd\n",
    "test_ids = test['TransactionID']\n",
    "if isinstance(proba, pd.DataFrame):\n",
    "    # Probability for positive class labeled 1\n",
    "    if 1 in proba.columns:\n",
    "        preds_pos = proba[1]\n",
    "    else:\n",
    "        # fallback if positive class label is 'True' or similar\n",
    "        pos_col = [c for c in proba.columns if str(c).lower() in ('1', 'true', 'yes')]\n",
    "        preds_pos = proba[pos_col[0]] if pos_col else proba.iloc[:, -1]\n",
    "else:\n",
    "    preds_pos = proba  # series of positive class probabilities\n",
    "\n",
    "sub = pd.DataFrame({'TransactionID': test_ids, 'isFraud': preds_pos})\n",
    "sub_path = 'submission.csv'\n",
    "sub.to_csv(sub_path, index=False)\n",
    "print('✅ Saved:', sub_path)\n",
    "!head -n 5 submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚚 Step 7: Submit to Kaggle (from Colab)\n",
    "If you haven't accepted the competition rules, the submission will fail—open the [competition page](https://www.kaggle.com/c/ieee-fraud-detection) and click **\"I Understand and Accept\"** first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Submit `submission.csv` to Kaggle\n",
    "message = \"AutoGluon baseline\"  #@param {type:\"string\"}\n",
    "competition = 'ieee-fraud-detection'\n",
    "try:\n",
    "    !kaggle competitions submit -c {competition} -f submission.csv -m \"$message\"\n",
    "except Exception as e:\n",
    "    print('\\n⚠️ Submission failed. Common causes:')\n",
    "    print('- You must accept competition rules on the website first')\n",
    "    print('- Kaggle API rate limits / auth issues')\n",
    "    print('- Missing `kaggle.json` or wrong permissions (chmod 600)')\n",
    "    print('\\nError:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏁 Step 8: (Optional) Peek at the leaderboard from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Show competition leaderboard (optional)\n",
    "competition = 'ieee-fraud-detection'\n",
    "!kaggle competitions leaderboard {competition} --show | head -n 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ✅ Tips for better scores\n",
    "- Increase training time or try `presets='best_quality'` (more accurate, slower)\n",
    "- Feature engineering: convert dates, count encodings, interactions\n",
    "- Tune with `predictor.fit(..., hyperparameters=...)`\n",
    "- Use cross-validation via `fold_strategy` / `num_bag_folds`\n",
    "- Enrich categorical handling with target encoding (careful with leakage)\n",
    "- Explore AutoGluon `leaderboard()` to inspect model performance\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AutoGluon_IEEE_Fraud_Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
