{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfwPLgTBjWn/1yFUPRmv4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshata4/data_mining/blob/main/apachebeam/apachebeam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "554d4c7b"
      },
      "source": [
        "This pipeline demonstrates several Apache Beam concepts:\n",
        "\n",
        "1.  **Pipeline I/O (`beam.io.ReadFromText`)**: Reads data from the `sample_data.txt` file, creating an initial `PCollection` of strings.\n",
        "2.  **Composite Transform (`ProcessData`)**: This is a custom transform that encapsulates a sequence of operations:\n",
        "    *   `SplitData` (`beam.Map`): Splits each input string by commas into a list of strings.\n",
        "    *   `FilterApples` (`beam.Filter`): Keeps only the elements where the third element (item name) is 'apple'.\n",
        "    *   `ExtractTimestamp` (`beam.Map`): This was originally intended to extract the timestamp but was modified in the composite transform to simply pass through the split elements. The actual timestamp extraction with a `TimestampedValue` is done in the subsequent `ParDo`.\n",
        "3.  **ParDo (`ExtractTimestampDoFn`)**: A custom `DoFn` is used to process each element. It parses the timestamp string from the element and associates a `TimestampedValue` with each element, which is necessary for windowing. Elements that cannot be processed are skipped.\n",
        "4.  **Windowing (`beam.WindowInto(FixedWindows(30 * 60))`)**: Groups elements into fixed windows of 30 minutes based on their timestamps. This allows for processing elements within specific time intervals.\n",
        "5.  **Map (`ExtractItemAndCount`)**: Transforms each element in the windowed data. It creates a tuple containing the original element and a count of 1. This structure is prepared for potential future aggregations (though not fully utilized in this example).\n",
        "6.  **Filter (`FilterCounts`)**: Keeps only the elements where the count is 1. In this simple case, it effectively passes all elements from the previous step, but demonstrates the use of a filter.\n",
        "7.  **Partition (`beam.Partition`)**: Splits the `PCollection` into multiple `PCollections` based on a partitioning function (`partition_by_item`). The `partition_by_item` function determines which output `PCollection` an element belongs to based on the item name (apple, banana, or other).\n",
        "8.  **Map (Printing Partitions)**: Separate `Map` transforms are applied to each partitioned `PCollection` to print the elements belonging to each partition.\n",
        "\n",
        "This example illustrates how these different transforms can be chained together to build a data processing pipeline in Apache Beam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c915c83",
        "outputId": "4a8511de-6581-4c20-b767-c8fffda69aad"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create a sample data file\n",
        "data = [\"1,2023-01-01 10:00:00,apple\",\n",
        "        \"2,2023-01-01 10:05:00,banana\",\n",
        "        \"3,2023-01-01 10:10:00,apple\",\n",
        "        \"4,2023-01-01 10:15:00,orange\",\n",
        "        \"5,2023-01-01 10:20:00,banana\",\n",
        "        \"6,2023-01-01 11:00:00,apple\",\n",
        "        \"7,2023-01-01 11:05:00,banana\",\n",
        "        \"8,2023-01-01 11:10:00,apple\",\n",
        "        \"9,2023-01-01 11:15:00,orange\",\n",
        "        \"10,2023-01-01 11:20:00,banana\"]\n",
        "\n",
        "with open('sample_data.txt', 'w') as f:\n",
        "    for line in data:\n",
        "        f.write(line + '\\n')\n",
        "\n",
        "print(\"Sample data generated in sample_data.txt\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data generated in sample_data.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f69558d6"
      },
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam import transforms\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.transforms.window import FixedWindows\n",
        "import re\n",
        "\n",
        "# Define a simple composite transform\n",
        "@beam.ptransform_fn\n",
        "def ProcessData(pcollection):\n",
        "    \"\"\"\n",
        "    A composite transform that processes the data.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        pcollection\n",
        "        | 'SplitData' >> beam.Map(lambda x: x.split(','))\n",
        "        | 'FilterApples' >> beam.Filter(lambda x: x[2] == 'apple')\n",
        "        | 'ExtractTimestamp' >> beam.Map(lambda x: (x[0], x[1], x[2])) # Keep all parts for now\n",
        "    )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ace579b",
        "outputId": "46b15537-d8be-495d-9425-e1379b5f2780"
      },
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.transforms.window import FixedWindows\n",
        "from datetime import datetime\n",
        "\n",
        "# Define a DoFn for ParDo\n",
        "class ExtractTimestampDoFn(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        try:\n",
        "            # Assuming the timestamp is the second element (index 1) after splitting\n",
        "            timestamp_str = element[1]\n",
        "            # Convert the timestamp string to a datetime object\n",
        "            timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')\n",
        "            # Yield the element with the timestamp\n",
        "            yield beam.window.TimestampedValue(element, timestamp.timestamp())\n",
        "        except (ValueError, IndexError) as e:\n",
        "            print(f\"Could not process element: {element}, error: {e}\")\n",
        "            return # Skip elements that cannot be processed\n",
        "\n",
        "\n",
        "# Define a partition function\n",
        "def partition_by_item(element, num_partitions):\n",
        "    \"\"\"Partitions elements based on the item name.\"\"\"\n",
        "    # Element is now a tuple of (original_element, count)\n",
        "    original_element = element[0]\n",
        "    item = original_element[2] # Access the item name from the original element\n",
        "    if item == 'apple':\n",
        "        return 0  # Partition 0 for apples\n",
        "    elif item == 'banana':\n",
        "        return 1  # Partition 1 for bananas\n",
        "    else:\n",
        "        return 2  # Partition 2 for others\n",
        "\n",
        "# Create and run the pipeline\n",
        "with beam.Pipeline(options=PipelineOptions()) as pipeline:\n",
        "    # Pipeline I/O: Read data from the text file\n",
        "    lines = pipeline | 'ReadData' >> beam.io.ReadFromText('sample_data.txt')\n",
        "\n",
        "    # Apply Composite Transform to split and filter data\n",
        "    split_data = lines | 'SplitAndFilter' >> ProcessData()\n",
        "\n",
        "    # Apply ParDo for timestamp extraction on the split data\n",
        "    processed_data = split_data | 'ExtractTimestamp' >> beam.ParDo(ExtractTimestampDoFn())\n",
        "\n",
        "    # Windowing: Apply fixed windows of 30 minutes\n",
        "    windowed_data = processed_data | 'FixedWindows' >> beam.WindowInto(FixedWindows(30 * 60))\n",
        "\n",
        "    # Map: Extract item and count (simple example)\n",
        "    # Modified to keep the original element along with the count\n",
        "    item_counts = windowed_data | 'ExtractItemAndCount' >> beam.Map(lambda x: (x, 1))\n",
        "\n",
        "    # Filter: Keep only items with count 1 (in this simple case)\n",
        "    filtered_counts = item_counts | 'FilterCounts' >> beam.Filter(lambda x: x[1] == 1)\n",
        "\n",
        "    # Partition: Partition data based on item name\n",
        "    partitioned_data = filtered_counts | 'PartitionByItem' >> beam.Partition(partition_by_item, 3)\n",
        "\n",
        "    # Process each partition (example: print elements in each partition)\n",
        "    apple_partition = partitioned_data[0] | 'PrintApples' >> beam.Map(lambda x: print(f\"Apple Partition: {x}\"))\n",
        "    banana_partition = partitioned_data[1] | 'PrintBananas' >> beam.Map(lambda x: print(f\"Banana Partition: {x}\"))\n",
        "    other_partition = partitioned_data[2] | 'PrintOthers' >> beam.Map(lambda x: print(f\"Other Partition: {x}\"))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-51dbd91e-4a25-4f21-96ef-b0d0739191b9.json']\n",
            "WARNING:apache_beam.transforms.core:Using yield and return in the process method of <class '__main__.ExtractTimestampDoFn'> can lead to unexpected behavior, see:https://github.com/apache/beam/issues/22969.\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-51dbd91e-4a25-4f21-96ef-b0d0739191b9.json']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-51dbd91e-4a25-4f21-96ef-b0d0739191b9.json']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple Partition: (('1', '2023-01-01 10:00:00', 'apple'), 1)\n",
            "Apple Partition: (('3', '2023-01-01 10:10:00', 'apple'), 1)\n",
            "Apple Partition: (('6', '2023-01-01 11:00:00', 'apple'), 1)\n",
            "Apple Partition: (('8', '2023-01-01 11:10:00', 'apple'), 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f583d1b7"
      },
      "source": [
        "Let's trace how the data changes as it flows through the pipeline:\n",
        "\n",
        "1.  **ReadData (`beam.io.ReadFromText`)**: The initial data is a `PCollection` of strings, where each string is a line read from the `sample_data.txt` file (e.g., `\"1,2023-01-01 10:00:00,apple\"`).\n",
        "2.  **SplitAndFilter (`ProcessData` composite transform)**:\n",
        "    *   `SplitData` (`beam.Map`): Each string is split by commas into a list of strings (e.g., `['1', '2023-01-01 10:00:00', 'apple']`).\n",
        "    *   `FilterApples` (`beam.Filter`): Only lists where the third element is 'apple' are kept (e.g., `['1', '2023-01-01 10:00:00', 'apple']` is kept, but `['2', '2023-01-01 10:05:00', 'banana']` is filtered out).\n",
        "    *   `ExtractTimestamp` (`beam.Map`): The structure remains a list of strings (e.g., `['1', '2023-01-01 10:00:00', 'apple']`).\n",
        "3.  **ExtractTimestamp (`beam.ParDo(ExtractTimestampDoFn)`)**: Each list of strings is wrapped in a `TimestampedValue` object, associating a timestamp with it. The structure is now a `PCollection` of `TimestampedValue` objects, each containing a list of strings (e.g., `TimestampedValue(['1', '2023-01-01 10:00:00', 'apple'], 1672567200.0)`).\n",
        "4.  **FixedWindows (`beam.WindowInto(FixedWindows(30 * 60))`)**: The `TimestampedValue` objects are grouped into windows based on their timestamps. The structure remains a `PCollection` of `TimestampedValue` objects, but now organized within windows.\n",
        "5.  **ExtractItemAndCount (`beam.Map`)**: Each `TimestampedValue` object's value (the list of strings) is paired with a count of 1. The structure becomes a `PCollection` of tuples, where each tuple contains the original list and the count (e.g., `(['1', '2023-01-01 10:00:00', 'apple'], 1)`).\n",
        "6.  **FilterCounts (`beam.Filter`)**: The structure remains a `PCollection` of tuples `(original_element, 1)`, but elements where the count is not 1 are removed (in this simple case, all elements are kept).\n",
        "7.  **PartitionByItem (`beam.Partition`)**: The `PCollection` is split into a list of `PCollection`s based on the item name (the third element of the original list within the tuple). Each resulting `PCollection` contains tuples `(original_element, 1)` for a specific item type (e.g., one `PCollection` for apples, one for bananas, one for others).\n",
        "8.  **Print Partitions (`beam.Map`)**: The elements in each partitioned `PCollection` are processed (in this case, printed to the console). The structure within each partition is still tuples `(original_element, 1)`."
      ]
    }
  ]
}