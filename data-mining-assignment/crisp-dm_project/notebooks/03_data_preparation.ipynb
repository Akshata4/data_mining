{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287bc07a",
   "metadata": {},
   "source": [
    "\n",
    "    ## CRISP-DM Phase 3: Data Preparation\n",
    "\n",
    "    This notebook describes the data preparation phase for the graduate admission dataset. \n",
    "    The dataset is split into train/validation/test sets, and necessary preprocessing steps are outlined.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c136e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv('graduate_admission1.csv')\n",
    "\n",
    "    # Check initial data structure\n",
    "    data.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ae370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    # Using an 80-10-10 split ratio\n",
    "    temp_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "    train_data, val_data = train_test_split(temp_data, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Save the splits to parquet files for reproducibility\n",
    "    train_data.to_parquet('data/processed/train.parquet', index=False)\n",
    "    val_data.to_parquet('data/processed/val.parquet', index=False)\n",
    "    test_data.to_parquet('data/processed/test.parquet', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5716dae",
   "metadata": {},
   "source": [
    "\n",
    "### Quality Profiling and Checks\n",
    "\n",
    "We conducted several quality checks on the processed dataset to ensure high data quality before modeling.\n",
    "Visualizations were generated to inspect missing values and other data characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275befd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the train dataset for profiling\n",
    "train_data = pd.read_parquet('data/processed/train.parquet')\n",
    "\n",
    "# Check for missing values and plot them\n",
    "missing_values = train_data.isnull().sum()\n",
    "plt.figure(figsize=(10, 6))\n",
    "missing_plot = sns.heatmap(train_data.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Values After Preprocessing')\n",
    "plt.savefig('assets/missingness_after.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save missing values to JSON report\n",
    "prep_checks = {\n",
    "    'missing_values_after_preprocessing': missing_values[missing_values > 0].to_dict()\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('reports/prep_checks.json', 'w') as json_file:\n",
    "    json.dump(prep_checks, json_file, indent=4)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
